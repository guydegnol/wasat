{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c795e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filedrive=\"/content/drive/My Drive/0Satellite_Images_Unsupervised/MNIST_PyTorch\"\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "filedrive=\"data/0Satellite_Images_Unsupervised/MNIST_PyTorch\"\n",
    "\n",
    "import torch, torchvision\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7418739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, bands_nb, patch_size):\n",
    "\n",
    "        input_size = (bands_nb, patch_size, patch_size)\n",
    "      \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 20)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(20, 10)\n",
    "        self.layer3 = nn.Linear(784*32, 10)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(bands_nb, 32, kernel_size=3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(32)\n",
    "        self.conv12 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(32)\n",
    "        self.conv13 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
    "\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "#        self.pool = nn.MaxPool2d(2, 2)\n",
    "#        self.l2norm = L2()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.conv11(x)) #        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x=F.relu(self.conv12(x))\n",
    "         # flatten all dimensions except batch\n",
    "#        x = F.relu(self.layer3(x))\n",
    "        x=F.relu(self.conv13(x))\n",
    "        return self.conv14(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbcbf487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/train-images-idx3-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/train-labels-idx1-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/t10k-images-idx3-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/0Satellite_Images_Unsupervised/MNIST_PyTorch/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/miniconda/envs/mlapp_py3.6/lib/python3.6/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=filedrive, train=True, transform=transform, download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=filedrive, train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5898998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2bf4f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eb569bf10c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# reshape mini-batch data to [N, 784] matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# load it to the active device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# reset the gradients back to zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstructions\n",
    "        outputs = model(batch_features)\n",
    "        #outputs = outputs.view(-1).to(device)\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "\n",
    "        train_loss = criterion(outputs, batch_labels.to(device))\n",
    "\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "\n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f950898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "total = 0\n",
    "correct = 0\n",
    "print(test_loader.dataset)\n",
    "for batch_features, labels in test_loader:\n",
    "    batch_features = batch_features.view(-1, 784).to(device)  \n",
    "    outputs = model(batch_features)\n",
    "    #print(outputs.shape)\n",
    "\n",
    "    #print('IMAGE')\n",
    "\n",
    "    #plt.imshow(batch_features[0].cpu().detach().view(28, 28).numpy())\n",
    "    #plt.show()     \n",
    "\n",
    "    #print(np.argmax(outputs[0].cpu().detach().numpy()))   \n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7ffba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlapp_py3.6",
   "language": "python",
   "name": "mlapp_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
